{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. Data loading and augmentation\n",
    "class MNISTBarlowTwinsDataset(datasets.MNIST):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(28, scale=(0.2, 1.0)),\n",
    "            transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "        \n",
    "        return self.transform(img), self.transform(img), target\n",
    "\n",
    "# 2. Barlow Twins model architecture\n",
    "class BarlowTwinsMNIST(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, feature_dim)\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(feature_dim, affine=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z = self.bn(z)\n",
    "        return z\n",
    "\n",
    "# 3. Barlow Twins loss function\n",
    "def barlow_twins_loss(z1, z2, lambda_param=5e-3):\n",
    "    batch_size = z1.shape[0]\n",
    "    feature_dim = z1.shape[1]\n",
    "    \n",
    "    c = torch.mm(z1.T, z2) / batch_size\n",
    "    c_diff = (c - torch.eye(feature_dim, device=device)).pow(2)\n",
    "    \n",
    "    off_diagonal = c_diff.flatten()[:-1].view(feature_dim - 1, feature_dim + 1)[:, 1:].flatten()\n",
    "    loss = c_diff.diagonal().sum() + lambda_param * off_diagonal.sum()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# 4. Pre-training function\n",
    "def pretrain_barlow_twins(model, train_loader, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        for data1, data2, _ in progress_bar:\n",
    "            data1, data2 = data1.to(device), data2.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            z1 = model(data1)\n",
    "            z2 = model(data2)\n",
    "            \n",
    "            loss = barlow_twins_loss(z1, z2)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        losses.append(avg_loss)\n",
    "        print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# 5. Classifier for fine-tuning\n",
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super().__init__()\n",
    "        self.encoder = pretrained_model.encoder\n",
    "        self.classifier = nn.Linear(128, 10)  # 10 classes for MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "# 6. Fine-tuning function\n",
    "def finetune(model, train_loader, test_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        for data, target in progress_bar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in tqdm(test_loader, desc='Evaluating'):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = model(data)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}, Test Accuracy: {accuracy:.2f}%')\n",
    "        model.train()\n",
    "\n",
    "# 7. Feature extraction function\n",
    "def extract_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(dataloader, desc='Extracting features'):\n",
    "            data = data.to(device)\n",
    "            feature = model(data)\n",
    "            features.append(feature.cpu().numpy())\n",
    "            labels.append(target.numpy())\n",
    "    return np.vstack(features), np.concatenate(labels)\n",
    "\n",
    "# 8. Visualization function\n",
    "def plot_embeddings(features, labels, method='UMAP'):\n",
    "    if method == 'UMAP':\n",
    "        reducer = UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "    elif method == 'PCA':\n",
    "        reducer = PCA(n_components=2, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be either 'UMAP' or 'PCA'\")\n",
    "    \n",
    "    embeddings = reducer.fit_transform(features)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(embeddings[:, 0], embeddings[:, 1], c=labels, cmap='tab10', s=5, alpha=0.7)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title(f'{method} visualization of Barlow Twins learned representations')\n",
    "    plt.xlabel(f'{method}_1')\n",
    "    plt.ylabel(f'{method}_2')\n",
    "    plt.savefig(f'barlow_twins_mnist_{method.lower()}.png')\n",
    "    plt.close()\n",
    "\n",
    "# 9. Main execution\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    batch_size = 256\n",
    "    feature_dim = 128\n",
    "    pretrain_epochs = 10\n",
    "    finetune_epochs = 10\n",
    "    \n",
    "    # Load MNIST dataset for pre-training\n",
    "    train_dataset = MNISTBarlowTwinsDataset('data', train=True, download=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    # Initialize model and optimizer for pre-training\n",
    "    model = BarlowTwinsMNIST(feature_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Pre-train the model\n",
    "    print(\"Starting pre-training...\")\n",
    "    pretrain_losses = pretrain_barlow_twins(model, train_loader, optimizer, epochs=pretrain_epochs)\n",
    "\n",
    "    # Plot pre-training loss\n",
    "    plt.plot(pretrain_losses)\n",
    "    plt.title('Barlow Twins Pre-training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig('barlow_twins_pretrain_loss.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Save the pre-trained model\n",
    "    torch.save(model.state_dict(), 'barlow_twins_pretrained_mnist.pth')\n",
    "    print(\"Pre-training complete!\")\n",
    "\n",
    "    # Prepare data for fine-tuning\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Initialize classifier for fine-tuning\n",
    "    classifier = MNISTClassifier(model).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "    # Fine-tune the model\n",
    "    print(\"Starting fine-tuning...\")\n",
    "    finetune(classifier, train_loader, test_loader, criterion, optimizer, epochs=finetune_epochs)\n",
    "\n",
    "    print(\"Fine-tuning complete!\")\n",
    "\n",
    "    # Extract features for visualization\n",
    "    features, labels = extract_features(classifier.encoder, test_loader)\n",
    "\n",
    "    # Plot UMAP\n",
    "    print(\"Generating UMAP visualization...\")\n",
    "    plot_embeddings(features, labels, method='UMAP')\n",
    "\n",
    "    # Plot PCA\n",
    "    print(\"Generating PCA visualization...\")\n",
    "    plot_embeddings(features, labels, method='PCA')\n",
    "\n",
    "    print(\"Visualizations complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
