{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def create_augmentation_model():\n",
    "    \"\"\"Create data augmentation model for MNIST images.\"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomTranslation(0.1, 0.1)\n",
    "    ])\n",
    "\n",
    "def create_encoder():\n",
    "    \"\"\"Create encoder model for MNIST images.\"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(32, 3, activation='relu'),\n",
    "        layers.Conv2D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(128, activation=None)  # No activation in the final layer\n",
    "    ])\n",
    "\n",
    "def create_projector(input_dim=128, hidden_dim=128, output_dim=64):\n",
    "    \"\"\"Create projector model.\"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Dense(hidden_dim, activation='relu', input_shape=(input_dim,)),\n",
    "        layers.Dense(output_dim, activation=None)\n",
    "    ])\n",
    "\n",
    "def create_predictor(input_dim=64, hidden_dim=64, output_dim=64):\n",
    "    \"\"\"Create predictor model.\"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Dense(hidden_dim, activation='relu', input_shape=(input_dim,)),\n",
    "        layers.Dense(output_dim, activation=None)\n",
    "    ])\n",
    "\n",
    "class SimSiam(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SimSiam, self).__init__()\n",
    "        self.encoder = create_encoder()\n",
    "        self.projector = create_projector()\n",
    "        self.predictor = create_predictor()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z1 = self.projector(self.encoder(inputs[0]))\n",
    "        z2 = self.projector(self.encoder(inputs[1]))\n",
    "        p1 = self.predictor(z1)\n",
    "        p2 = self.predictor(z2)\n",
    "        return p1, p2, z1, z2\n",
    "\n",
    "@tf.function\n",
    "def simsiam_loss(p1, p2, z1, z2):\n",
    "    \"\"\"Compute SimSiam loss.\"\"\"\n",
    "    # Stop gradient for z1 and z2\n",
    "    z1 = tf.stop_gradient(z1)\n",
    "    z2 = tf.stop_gradient(z2)\n",
    "\n",
    "    # Normalize the projections and predictions\n",
    "    p1 = tf.math.l2_normalize(p1, axis=1)\n",
    "    p2 = tf.math.l2_normalize(p2, axis=1)\n",
    "    z1 = tf.math.l2_normalize(z1, axis=1)\n",
    "    z2 = tf.math.l2_normalize(z2, axis=1)\n",
    "\n",
    "    # Negative cosine similarity\n",
    "    loss = -0.5 * (tf.reduce_mean(tf.reduce_sum(p1 * z2, axis=1)) +\n",
    "                   tf.reduce_mean(tf.reduce_sum(p2 * z1, axis=1)))\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, optimizer, x1, x2):\n",
    "    \"\"\"Perform a single training step.\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        p1, p2, z1, z2 = model([x1, x2])\n",
    "        loss = simsiam_loss(p1, p2, z1, z2)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def train_simsiam(model, train_dataset, optimizer, epochs):\n",
    "    \"\"\"Train the SimSiam model.\"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        for x1, x2 in train_dataset:\n",
    "            loss = train_step(model, optimizer, x1, x2)\n",
    "            total_loss += loss\n",
    "            num_batches += 1\n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "def linear_evaluation(encoder, x_train, y_train, x_test, y_test):\n",
    "    \"\"\"Perform linear evaluation of the learned representations.\"\"\"\n",
    "    features_train = encoder.predict(x_train)\n",
    "    features_test = encoder.predict(x_test)\n",
    "\n",
    "    classifier = tf.keras.Sequential([\n",
    "        layers.Dense(10, activation='softmax', input_shape=(128,))\n",
    "    ])\n",
    "    classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    classifier.fit(features_train, y_train, epochs=100, batch_size=256, validation_split=0.2, verbose=0)\n",
    "\n",
    "    _, accuracy = classifier.evaluate(features_test, y_test, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "def extract_features(encoder, data):\n",
    "    \"\"\"Extract features using the trained encoder.\"\"\"\n",
    "    return encoder.predict(data)\n",
    "\n",
    "def plot_embeddings(features, labels, method='PCA'):\n",
    "    \"\"\"Plot embeddings using PCA or UMAP.\"\"\"\n",
    "    if method == 'PCA':\n",
    "        reducer = PCA(n_components=2, random_state=42)\n",
    "    elif method == 'UMAP':\n",
    "        reducer = UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be either 'PCA' or 'UMAP'\")\n",
    "    \n",
    "    embeddings = reducer.fit_transform(features)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(embeddings[:, 0], embeddings[:, 1], c=labels, cmap='tab10', s=5, alpha=0.7)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title(f'{method} visualization of SimSiam learned representations')\n",
    "    plt.xlabel(f'{method}_1')\n",
    "    plt.ylabel(f'{method}_2')\n",
    "    plt.savefig(f'simsiam_mnist_{method.lower()}_tf.png')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess MNIST data\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "    # Create augmentation model\n",
    "    augmentation = create_augmentation_model()\n",
    "\n",
    "    # Create dataset\n",
    "    def augment_pair(image, _):\n",
    "        return augmentation(image), augmentation(image)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(10000).map(augment_pair).batch(256).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Create and train SimSiam model\n",
    "    simsiam_model = SimSiam()\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    print(\"Training SimSiam model...\")\n",
    "    train_simsiam(simsiam_model, train_dataset, optimizer, epochs=50)\n",
    "\n",
    "    # Linear evaluation\n",
    "    print(\"Performing linear evaluation...\")\n",
    "    accuracy = linear_evaluation(simsiam_model.encoder, x_train, y_train, x_test, y_test)\n",
    "    print(f\"Linear evaluation accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Extract features\n",
    "    print(\"Extracting features...\")\n",
    "    train_features = extract_features(simsiam_model.encoder, x_train)\n",
    "    test_features = extract_features(simsiam_model.encoder, x_test)\n",
    "\n",
    "    # Visualize with PCA\n",
    "    print(\"Generating PCA visualization...\")\n",
    "    plot_embeddings(test_features, y_test, method='PCA')\n",
    "\n",
    "    # Visualize with UMAP\n",
    "    print(\"Generating UMAP visualization...\")\n",
    "    plot_embeddings(test_features, y_test, method='UMAP')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
