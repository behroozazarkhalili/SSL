{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 256\n",
    "        self.feature_dim = 128\n",
    "        self.pred_dim = 128\n",
    "        self.learning_rate = 0.03\n",
    "        self.momentum = 0.99\n",
    "        self.weight_decay = 1e-4\n",
    "        self.epochs = 100\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, split='train'):\n",
    "        self.dataset = datasets.MNIST(root='./data', train=(split == 'train'), download=True,\n",
    "                                      transform=transforms.ToTensor())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        return {'image': img, 'label': label}\n",
    "\n",
    "    def augment(self, image):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(28, scale=(0.2, 1.0)),\n",
    "            transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "        ])\n",
    "        return transform(image)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    def __init__(self, feature_dim, pred_dim):\n",
    "        super().__init__()\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(feature_dim, pred_dim),\n",
    "            nn.BatchNorm1d(pred_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(pred_dim, feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.predictor(x)\n",
    "\n",
    "class DirectPred(nn.Module):\n",
    "    def __init__(self, feature_dim, pred_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(feature_dim)\n",
    "        self.predictor = Predictor(feature_dim, pred_dim)\n",
    "        self.target_encoder = Encoder(feature_dim)\n",
    "\n",
    "        # Initialize target_encoder with encoder's parameters\n",
    "        self.target_encoder.load_state_dict(self.encoder.state_dict())\n",
    "\n",
    "        # Freeze target_encoder\n",
    "        for param in self.target_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        z1 = self.encoder(x1)\n",
    "        z2 = self.encoder(x2)\n",
    "        p1 = self.predictor(z1)\n",
    "        p2 = self.predictor(z2)\n",
    "        with torch.no_grad():\n",
    "            t1 = self.target_encoder(x1)\n",
    "            t2 = self.target_encoder(x2)\n",
    "        return p1, p2, t1.detach(), t2.detach()\n",
    "\n",
    "class DirectPredTrainer:\n",
    "    def __init__(self, model: DirectPred, train_loader: DataLoader, optimizer: optim.Optimizer, device: torch.device, momentum: float):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def train(self, epochs: int):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for batch in tqdm(self.train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
    "                x = batch['image'].to(self.device)\n",
    "                x1 = self.train_loader.dataset.augment(x)\n",
    "                x2 = self.train_loader.dataset.augment(x)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                p1, p2, t1, t2 = self.model(x1, x2)\n",
    "                loss = self._directpred_loss(p1, p2, t1, t2)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                self._update_target_encoder()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(self.train_loader):.4f}\")\n",
    "\n",
    "    def _directpred_loss(self, p1, p2, t1, t2):\n",
    "        loss = nn.functional.mse_loss(p1, t2) + nn.functional.mse_loss(p2, t1)\n",
    "        return loss\n",
    "\n",
    "    def _update_target_encoder(self):\n",
    "        for online_params, target_params in zip(self.model.encoder.parameters(), self.model.target_encoder.parameters()):\n",
    "            target_params.data = self.momentum * target_params.data + (1 - self.momentum) * online_params.data\n",
    "\n",
    "class DirectPredEvaluator:\n",
    "    def __init__(self, model: DirectPred, train_loader: DataLoader, test_loader: DataLoader, device: torch.device):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "\n",
    "    def evaluate(self):\n",
    "        linear_metrics = self._linear_evaluation()\n",
    "        knn_metrics = self._knn_evaluation()\n",
    "        return linear_metrics, knn_metrics\n",
    "\n",
    "    def _linear_evaluation(self):\n",
    "        train_features, train_labels = self._extract_features(self.train_loader)\n",
    "        test_features, test_labels = self._extract_features(self.test_loader)\n",
    "\n",
    "        classifier = nn.Linear(train_features.shape[1], 10).to(self.device)  # 10 classes for MNIST\n",
    "        optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(10):  # Train for 10 epochs\n",
    "            for i in range(0, len(train_features), 256):\n",
    "                batch_features = train_features[i:i+256].to(self.device)\n",
    "                batch_labels = train_labels[i:i+256].to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = classifier(batch_features)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = classifier(test_features.to(self.device))\n",
    "            _, predicted = torch.max(test_outputs, 1)\n",
    "            accuracy = accuracy_score(test_labels.cpu().numpy(), predicted.cpu().numpy())\n",
    "        return {'accuracy': accuracy}\n",
    "\n",
    "    def _knn_evaluation(self, k=5):\n",
    "        train_features, train_labels = self._extract_features(self.train_loader)\n",
    "        test_features, test_labels = self._extract_features(self.test_loader)\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(train_features.cpu().numpy(), train_labels.cpu().numpy())\n",
    "        predictions = knn.predict(test_features.cpu().numpy())\n",
    "        accuracy = accuracy_score(test_labels.cpu().numpy(), predictions)\n",
    "        return {'accuracy': accuracy}\n",
    "\n",
    "    def _extract_features(self, loader):\n",
    "        self.model.eval()\n",
    "        features, labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                images = batch['image'].to(self.device)\n",
    "                feature = self.model.encoder(images)\n",
    "                features.append(feature.cpu())\n",
    "                labels.append(batch['label'])\n",
    "        return torch.cat(features), torch.cat(labels)\n",
    "\n",
    "def main():\n",
    "    config = Config()\n",
    "\n",
    "    train_dataset = MNISTDataset(split='train')\n",
    "    test_dataset = MNISTDataset(split='test')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    model = DirectPred(config.feature_dim, config.pred_dim).to(config.device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config.learning_rate, momentum=0.9, weight_decay=config.weight_decay)\n",
    "\n",
    "    trainer = DirectPredTrainer(model, train_loader, optimizer, config.device, config.momentum)\n",
    "    evaluator = DirectPredEvaluator(model, train_loader, test_loader, config.device)\n",
    "\n",
    "    print(\"Starting DirectPred training...\")\n",
    "    trainer.train(config.epochs)\n",
    "\n",
    "    print(\"\\nEvaluating the model...\")\n",
    "    linear_metrics, knn_metrics = evaluator.evaluate()\n",
    "\n",
    "    print(\"\\nLinear Evaluation Metrics:\")\n",
    "    for key, value in linear_metrics.items():\n",
    "        print(f\"{key.capitalize()}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nKNN Evaluation Metrics:\")\n",
    "    for key, value in knn_metrics.items():\n",
    "        print(f\"{key.capitalize()}: {value:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
