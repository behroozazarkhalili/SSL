{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTBYOLDataset:\n",
    "    \"\"\"\n",
    "    Custom MNIST dataset for BYOL that returns two augmented versions of each image.\n",
    "    \"\"\"\n",
    "    def __init__(self, x: np.ndarray, y: np.ndarray, batch_size: int = 32):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def augment(self, image: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"Apply random augmentations to the input image.\"\"\"\n",
    "        image = tf.image.random_crop(image, size=[28, 28, 1])\n",
    "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "        image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "        return image\n",
    "\n",
    "    def __call__(self) -> tf.data.Dataset:\n",
    "        \"\"\"Create and return a tf.data.Dataset.\"\"\"\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.x, self.y))\n",
    "        dataset = dataset.shuffle(10000)\n",
    "        dataset = dataset.map(lambda x, y: (self.augment(x), self.augment(x), y),\n",
    "                              num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.batch(self.batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "class EncoderNetwork(keras.Model):\n",
    "    \"\"\"\n",
    "    Encoder network for BYOL.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim: int = 256):\n",
    "        super(EncoderNetwork, self).__init__()\n",
    "        self.encoder = keras.Sequential([\n",
    "            layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "            layers.Conv2D(64, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(2),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(feature_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        return self.encoder(x)\n",
    "\n",
    "class ProjectionNetwork(keras.Model):\n",
    "    \"\"\"\n",
    "    Projection network for BYOL.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int = 256, hidden_dim: int = 256, output_dim: int = 128):\n",
    "        super(ProjectionNetwork, self).__init__()\n",
    "        self.projection = keras.Sequential([\n",
    "            layers.Dense(hidden_dim, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(output_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        return self.projection(x)\n",
    "\n",
    "class PredictionNetwork(keras.Model):\n",
    "    \"\"\"\n",
    "    Prediction network for BYOL.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int = 128, hidden_dim: int = 256, output_dim: int = 128):\n",
    "        super(PredictionNetwork, self).__init__()\n",
    "        self.prediction = keras.Sequential([\n",
    "            layers.Dense(hidden_dim, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(output_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        return self.prediction(x)\n",
    "\n",
    "class BYOL(keras.Model):\n",
    "    \"\"\"\n",
    "    BYOL model combining encoder, projection, and prediction networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim: int = 256, projection_dim: int = 128):\n",
    "        super(BYOL, self).__init__()\n",
    "        self.online_encoder = EncoderNetwork(feature_dim)\n",
    "        self.online_projector = ProjectionNetwork(feature_dim, feature_dim, projection_dim)\n",
    "        self.online_predictor = PredictionNetwork(projection_dim, feature_dim, projection_dim)\n",
    "        \n",
    "        self.target_encoder = EncoderNetwork(feature_dim)\n",
    "        self.target_projector = ProjectionNetwork(feature_dim, feature_dim, projection_dim)\n",
    "        \n",
    "        # Build models\n",
    "        dummy_input = tf.keras.Input(shape=(28, 28, 1))\n",
    "        self.online_encoder(dummy_input)\n",
    "        self.online_projector(self.online_encoder(dummy_input))\n",
    "        self.online_predictor(self.online_projector(self.online_encoder(dummy_input)))\n",
    "        self.target_encoder(dummy_input)\n",
    "        self.target_projector(self.target_encoder(dummy_input))\n",
    "        \n",
    "        # Initialize target network with online network's parameters\n",
    "        self.target_encoder.set_weights(self.online_encoder.get_weights())\n",
    "        self.target_projector.set_weights(self.online_projector.get_weights())\n",
    "\n",
    "    def call(self, x1: tf.Tensor, x2: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "        # Online network forward pass\n",
    "        online_feat1 = self.online_encoder(x1)\n",
    "        online_proj1 = self.online_projector(online_feat1)\n",
    "        online_pred1 = self.online_predictor(online_proj1)\n",
    "        \n",
    "        online_feat2 = self.online_encoder(x2)\n",
    "        online_proj2 = self.online_projector(online_feat2)\n",
    "        online_pred2 = self.online_predictor(online_proj2)\n",
    "        \n",
    "        # Target network forward pass\n",
    "        target_feat1 = self.target_encoder(x1)\n",
    "        target_proj1 = self.target_projector(target_feat1)\n",
    "        \n",
    "        target_feat2 = self.target_encoder(x2)\n",
    "        target_proj2 = self.target_projector(target_feat2)\n",
    "        \n",
    "        return online_pred1, online_pred2, target_proj1, target_proj2\n",
    "@tf.function\n",
    "def byol_loss(online_pred1: tf.Tensor, online_pred2: tf.Tensor, \n",
    "               target_proj1: tf.Tensor, target_proj2: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Compute BYOL loss.\n",
    "    \"\"\"\n",
    "    loss1 = tf.reduce_mean(tf.losses.cosine_similarity(online_pred1, tf.stop_gradient(target_proj2), axis=-1))\n",
    "    loss2 = tf.reduce_mean(tf.losses.cosine_similarity(online_pred2, tf.stop_gradient(target_proj1), axis=-1))\n",
    "    return (loss1 + loss2) / 2\n",
    "\n",
    "@tf.function\n",
    "def train_step(model: BYOL, x1: tf.Tensor, x2: tf.Tensor, optimizer: tf.keras.optimizers.Optimizer) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Perform a single training step.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        online_pred1, online_pred2, target_proj1, target_proj2 = model(x1, x2)\n",
    "        loss = byol_loss(online_pred1, online_pred2, target_proj1, target_proj2)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def update_moving_average(online_model: keras.Model, target_model: keras.Model, beta: float = 0.99):\n",
    "    \"\"\"\n",
    "    Update moving average of target network.\n",
    "    \"\"\"\n",
    "    for online_weights, target_weights in zip(online_model.get_weights(), target_model.get_weights()):\n",
    "        target_weights = beta * target_weights + (1 - beta) * online_weights\n",
    "        target_model.set_weights([target_weights if w.shape == target_weights.shape else w for w in target_model.get_weights()])\n",
    "\n",
    "@tf.function\n",
    "def train_step(model: BYOL, x1: tf.Tensor, x2: tf.Tensor, optimizer: tf.keras.optimizers.Optimizer) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Perform a single training step.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        online_pred1, online_pred2, target_proj1, target_proj2 = model(x1, x2)\n",
    "        loss = byol_loss(online_pred1, online_pred2, target_proj1, target_proj2)\n",
    "    \n",
    "    trainable_vars = (model.online_encoder.trainable_variables + \n",
    "                      model.online_projector.trainable_variables + \n",
    "                      model.online_predictor.trainable_variables)\n",
    "    gradients = tape.gradient(loss, trainable_vars)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "    return loss\n",
    "\n",
    "def train_byol(model: BYOL, train_dataset: tf.data.Dataset, optimizer: tf.keras.optimizers.Optimizer, \n",
    "               epochs: int = 100) -> List[float]:\n",
    "    \"\"\"\n",
    "    Train the BYOL model.\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_idx, (x1, x2, _) in enumerate(train_dataset):\n",
    "            loss = train_step(model, x1, x2, optimizer)\n",
    "            epoch_loss += loss.numpy()\n",
    "            \n",
    "            update_moving_average(model.online_encoder, model.target_encoder)\n",
    "            update_moving_average(model.online_projector, model.target_projector)\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{batch_idx}], Loss: {loss.numpy():.4f}\")\n",
    "        \n",
    "        avg_loss = epoch_loss / (batch_idx + 1)\n",
    "        losses.append(avg_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "class MNISTClassifier(keras.Model):\n",
    "    \"\"\"\n",
    "    Classifier for MNIST using the pre-trained BYOL encoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder: EncoderNetwork):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        features = self.encoder(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "def train_classifier(model: MNISTClassifier, train_dataset: tf.data.Dataset, test_dataset: tf.data.Dataset, \n",
    "                     optimizer: tf.keras.optimizers.Optimizer, epochs: int = 10):\n",
    "    \"\"\"\n",
    "    Fine-tune the classifier on MNIST.\n",
    "    \"\"\"\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x, training=True)\n",
    "            loss_value = loss_fn(y, logits)\n",
    "        gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        train_acc_metric.update_state(y, logits)\n",
    "        return loss_value\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(x, y):\n",
    "        logits = model(x, training=False)\n",
    "        test_acc_metric.update_state(y, logits)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for x1, _, y in train_dataset:  # Use only the first augmented view\n",
    "            loss_value = train_step(x1, y)\n",
    "\n",
    "        train_acc = train_acc_metric.result()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss_value.numpy():.4f}, Accuracy: {train_acc.numpy():.4f}\")\n",
    "\n",
    "        for x, y in test_dataset:\n",
    "            test_step(x, y)\n",
    "\n",
    "        test_acc = test_acc_metric.result()\n",
    "        print(f\"Test Accuracy: {test_acc.numpy():.4f}\")\n",
    "\n",
    "        train_acc_metric.reset_states()\n",
    "        test_acc_metric.reset_states()\n",
    "\n",
    "def extract_features(model: keras.Model, dataset: tf.data.Dataset) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract features using the trained encoder.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    for x, y in dataset:\n",
    "        feature = model.encoder(x, training=False)\n",
    "        features.append(feature.numpy())\n",
    "        labels.append(y.numpy())\n",
    "    return np.vstack(features), np.concatenate(labels)\n",
    "\n",
    "def plot_embeddings(features: np.ndarray, labels: np.ndarray, method: str = 'UMAP'):\n",
    "    \"\"\"\n",
    "    Plot embeddings using UMAP or PCA.\n",
    "    \"\"\"\n",
    "    if method == 'UMAP':\n",
    "        reducer = UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "    elif method == 'PCA':\n",
    "        reducer = PCA(n_components=2, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be either 'UMAP' or 'PCA'\")\n",
    "    \n",
    "    embeddings = reducer.fit_transform(features)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(embeddings[:, 0], embeddings[:, 1], c=labels, cmap='tab10', s=5, alpha=0.7)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title(f'{method} visualization of BYOL learned representations')\n",
    "    plt.xlabel(f'{method}_1')\n",
    "    plt.ylabel(f'{method}_2')\n",
    "    plt.savefig(f'byol_mnist_{method.lower()}_tf.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # Load MNIST dataset\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = MNISTBYOLDataset(x_train, y_train, batch_size=256)()\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(256)\n",
    "\n",
    "    # Initialize BYOL model\n",
    "    byol_model = BYOL()\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Train BYOL\n",
    "    print(\"Starting BYOL training...\")\n",
    "    losses = train_byol(byol_model, train_dataset, optimizer, epochs=10)\n",
    "\n",
    "    # Plot BYOL training loss\n",
    "    plt.plot(losses)\n",
    "    plt.title('BYOL Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig('byol_training_loss_tf.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Initialize and train classifier\n",
    "    classifier = MNISTClassifier(byol_model.online_encoder)\n",
    "    classifier_optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "    print(\"Starting classifier fine-tuning...\")\n",
    "    train_classifier(classifier, train_dataset, test_dataset, classifier_optimizer, epochs=10)\n",
    "\n",
    "    # Extract features and create visualizations\n",
    "    features, labels = extract_features(classifier, test_dataset)\n",
    "\n",
    "    print(\"Generating UMAP visualization...\")\n",
    "    plot_embeddings(features, labels, method='UMAP')\n",
    "\n",
    "    print(\"Generating PCA visualization...\")\n",
    "    plot_embeddings(features, labels, method='PCA')\n",
    "\n",
    "    print(\"BYOL training and evaluation complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
